import streamlit as st
import pandas as pd
import io
import requests
from PIL import Image
from datetime import datetime
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase.pdfmetrics import stringWidth
from reportlab.lib.utils import ImageReader
import time
from pathlib import Path
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
import re
import unicodedata as _ud

# =========================
# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆåŒæ¢±å‰æï¼‰
#  Base : IPAexGothic.ttfï¼ˆæœ¬æ–‡ï¼‰
#  Fallback: NotoSansSymbols2-Regular.ttfï¼ˆæ­¯ç§‘è¨˜å· âŠ/â‰/âŒ/âŒŸ/âŒœ/âŒ ã»ã‹ï¼‰
# =========================
SYM_FALLBACK_NAME = "SymFallback"

def _setup_font():
    here = Path(__file__).parent
    fonts_dir = here / "fonts"
    fonts_dir.mkdir(exist_ok=True)

    # æœ¬æ–‡ï¼ˆæ—¥æœ¬èªï¼‰
    ipa = fonts_dir / "IPAexGothic.ttf"
    if ipa.exists():
        pdfmetrics.registerFont(TTFont("BaseJP", str(ipa)))
        base_font_name = "BaseJP"
    else:
        pdfmetrics.registerFont(UnicodeCIDFont("HeiseiKakuGo-W5"))
        base_font_name = "HeiseiKakuGo-W5"
        st.warning("âš ï¸ fonts/IPAexGothic.ttf ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ HeiseiKakuGo-W5 ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")

    # è¨˜å·ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    sym_candidates = [
        fonts_dir / "NotoSansSymbols2-Regular.ttf",
        here / "NotoSansSymbols2-Regular.ttf",
        Path("/System/Library/Fonts/Supplemental/NotoSansSymbols2-Regular.ttf"),
        Path("C:/Windows/Fonts/NotoSansSymbols2-Regular.ttf"),
    ]
    for p in sym_candidates:
        if p.exists():
            pdfmetrics.registerFont(TTFont(SYM_FALLBACK_NAME, str(p)))
            break
    else:
        st.error("âŒ è¨˜å·ç”¨ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`fonts/NotoSansSymbols2-Regular.ttf` ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")

    return base_font_name

JAPANESE_FONT = _setup_font()

# ========= è¨˜å·åˆ¤å®šï¼ˆã“ã“ã§ã‚·ãƒ³ãƒœãƒ«ç”¨ãƒ•ã‚©ãƒ³ãƒˆã¸æŒ¯ã‚‹ï¼‰=========
PALMER_SYMBOLS = set("âŒœâŒâŒâŒŸâŒâ‹âŠâ‰â¿â€â€²â€³Ê¼Ê¹ï¹…ï¹†")

def _needs_symbol_font(ch: str) -> bool:
    cp = ord(ch)
    if ch in PALMER_SYMBOLS:
        return True
    ranges = [
        (0x2500, 0x257F),  # Box Drawing
        (0x2580, 0x259F),  # Block Elements
        (0x25A0, 0x25FF),  # Geometric Shapes
        (0x2190, 0x21FF),  # Arrows
        (0x2300, 0x23FF),  # Misc Technicalï¼ˆâŠ/â‰/âŒâ€¦ ã‚’å«ã‚€ï¼‰
        (0x2200, 0x22FF),  # Math Operators
        (0x2070, 0x209F),  # Sup/Sub
        (0x02B0, 0x02FF),  # Modifier Letters
        (0x0300, 0x036F),  # Combining
        (0xFFE0, 0xFFEE),  # å…¨è§’è¨˜å·ï¼ˆä¿é™ºï¼‰
    ]
    for a, b in ranges:
        if a <= cp <= b:
            return True
    cat = _ud.category(ch)
    if cat in {"Sm", "So", "Sk"}:
        return True
    return False

def draw_with_fallback(c, x, y, text, base_font, size, sym_font=SYM_FALLBACK_NAME):
    """æ–‡å­—å˜ä½ã§ãƒ™ãƒ¼ã‚¹/è¨˜å·ãƒ•ã‚©ãƒ³ãƒˆã‚’åˆ‡æ›¿ãˆã¦1è¡Œæç”»ï¼ˆç½®æ›ã¯ã—ãªã„ï¼åŸæ–‡å³å¯†å‡ºåŠ›ï¼‰"""
    pen_x = x
    buf = ""
    cur_font = base_font
    registered = set(pdfmetrics.getRegisteredFontNames())

    def flush(seg, font_name):
        nonlocal pen_x
        if not seg:
            return
        c.setFont(font_name, size)
        c.drawString(pen_x, y, seg)
        pen_x += stringWidth(seg, font_name, size)

    for ch in (text or ""):
        use_sym = _needs_symbol_font(ch) and (sym_font in registered)
        target = sym_font if use_sym else base_font
        if target != cur_font:
            flush(buf, cur_font)
            buf = ch
            cur_font = target
        else:
            buf += ch
    flush(buf, cur_font)
    c.setFont(base_font, size)

# ====== ï¼ˆä»»æ„ï¼‰ä»£æ›¿è¡¨ç¤ºãƒˆã‚°ãƒ«ï¼šãƒ•ã‚©ãƒ³ãƒˆãŒç„¡ã„ç’°å¢ƒã ã‘ä½¿ã† ======
st.sidebar.markdown("### âš™ï¸ PDFã®æ­¯å¼è¨˜å·")
use_fallback = st.sidebar.checkbox("ãƒ•ã‚©ãƒ³ãƒˆãŒç„¡ã„å ´åˆã ã‘ä»£æ›¿è¨˜å·ã§æãï¼ˆâ”¬/â”´/â”/â”˜/â”Œ/â””ï¼‰", value=False)

DENTAL_SAFE_FALLBACK = {
    # ã‚¢ãƒ¼ãƒï¼ˆä¸¡å´ï¼‰
    "\u23CA": "\u252C",  # âŠ (UP+HORIZONTAL=ä¸Šé¡) -> â”¬
    "\u23C9": "\u2534",  # â‰ (DOWN+HORIZONTAL=ä¸‹é¡) -> â”´
    # è±¡é™ï¼ˆç‰‡å´ï¼‰
    "\u231D": "\u2510",  # å³ä¸Š âŒ -> â”
    "\u231F": "\u2518",  # å³ä¸‹ âŒŸ -> â”˜
    "\u231C": "\u250C",  # å·¦ä¸Š âŒœ -> â”Œ
    "\u231E": "\u2514",  # å·¦ä¸‹ âŒ -> â””
}
def _maybe_fallback_for_pdf(s: str) -> str:
    if not use_fallback:
        return s  # å³å¯†ãƒ¢ãƒ¼ãƒ‰ï¼šä¸€åˆ‡ç½®æ›ã—ãªã„
    return "".join(DENTAL_SAFE_FALLBACK.get(ch, ch) for ch in (s or ""))

# =========================
# ã‚¢ãƒ—ãƒªæœ¬ä½“
# =========================
st.set_page_config(page_title="ğŸ” å­¦ç”ŸæŒ‡å°ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", layout="wide")
st.title("ğŸ” å­¦ç”ŸæŒ‡å°ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")

# ãƒ•ã‚©ãƒ³ãƒˆç¢ºèªï¼†ç‰¹æ®Šæ–‡å­—è¨ºæ–­
with st.expander("ğŸ§ª ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²ç¢ºèª / ç‰¹æ®Šæ–‡å­—è¨ºæ–­", expanded=False):
    cols = st.columns(3)
    with cols[0]:
        if st.button("ç™»éŒ²æ¸ˆã¿ãƒ•ã‚©ãƒ³ãƒˆã‚’è¡¨ç¤º"):
            st.write(sorted(pdfmetrics.getRegisteredFontNames()))
    with cols[1]:
        st.caption("ãƒ’ãƒƒãƒˆ1ä»¶ç›®ã‹ã‚‰æ—¥æœ¬èªãƒ»è‹±æ•°ä»¥å¤–ã®æ–‡å­—ã‚’æŠ½å‡ºã—ã¦è¡¨ç¤ºã—ã¾ã™")
        if st.button("ç‰¹æ®Šæ–‡å­—ã‚’æŠ½å‡º"):
            if "df_filtered" in st.session_state and len(st.session_state["df_filtered"]) > 0:
                txt = st.session_state["diagnostic_text"]
                specials = []
                for ch in txt:
                    if ch.isalnum() or ch in " ã€€ã€ã€‚ãƒ»ï¼Œï¼()ï¼ˆï¼‰[]ã€ã€‘{}ï½›ï½:ï¼š;ï¼›!?ï¼ï¼Ÿ+-/ï¼…%ï¼,ï¼":
                        continue
                    try:
                        name = _ud.name(ch)
                    except Exception:
                        name = "(no name)"
                    specials.append({"char": ch, "U+": f"U+{ord(ch):04X}", "name": name})
                st.write(specials if specials else "ç‰¹æ®Šæ–‡å­—ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.write("ã¾ãšæ¤œç´¢ã—ã¦ãƒ’ãƒƒãƒˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚")
    with cols[2]:
        st.caption("PDFã«å…¥ã‚‹æ–‡å­—ã‚’ç¢ºèªï¼ˆå…ˆé ­120æ–‡å­—ï¼‰")
        if st.button("PDFã«æµã™æ–‡å­—ã‚’è¡¨ç¤º"):
            if "df_filtered" in st.session_state and len(st.session_state["df_filtered"]) > 0:
                raw = st.session_state["diagnostic_text"]
                prepared = _maybe_fallback_for_pdf(raw)
                st.write({"raw": raw[:120], "pdf_input": prepared[:120], "fallback_mode": use_fallback})
            else:
                st.write("ã¾ãšæ¤œç´¢ã—ã¦ãƒ’ãƒƒãƒˆã‚’å‡ºã—ã¦ãã ã•ã„ã€‚")

# ===== åˆ—åæ­£è¦åŒ– & å®‰å…¨å–å¾— =====
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    def _clean(s):
        s = str(s).replace("\ufeff", "")
        return re.sub(r"[\u3000 \t\r\n]+", "", s)
    df = df.copy()
    df.columns = [_clean(c) for c in df.columns]
    alias = {
        "å•é¡Œæ–‡":  ["è¨­å•", "å•é¡Œ", "æœ¬æ–‡"],
        "é¸æŠè‚¢1": ["é¸æŠè‚¢ï¼¡","é¸æŠè‚¢a","A","ï½"],
        "é¸æŠè‚¢2": ["é¸æŠè‚¢ï¼¢","é¸æŠè‚¢b","B","ï½‚"],
        "é¸æŠè‚¢3": ["é¸æŠè‚¢ï¼£","é¸æŠè‚¢c","C","ï½ƒ"],
        "é¸æŠè‚¢4": ["é¸æŠè‚¢ï¼¤","é¸æŠè‚¢d","D","ï½„"],
        "é¸æŠè‚¢5": ["é¸æŠè‚¢ï¼¥","é¸æŠè‚¢e","E","ï½…"],
        "æ­£è§£":    ["è§£ç­”","ç­”ãˆ","ans","answer"],
        "ç§‘ç›®åˆ†é¡": ["åˆ†é¡","ç§‘ç›®","ã‚«ãƒ†ã‚´ãƒª","ã‚«ãƒ†ã‚´ãƒªãƒ¼"],
        "ãƒªãƒ³ã‚¯URL": ["ç”»åƒURL","ç”»åƒãƒªãƒ³ã‚¯","ãƒªãƒ³ã‚¯","ç”»åƒLink"],
    }
    colset = set(df.columns)
    for canon, cands in alias.items():
        if canon in colset: continue
        for c in cands:
            if c in colset:
                df.rename(columns={c: canon}, inplace=True)
                colset.add(canon)
                break
    return df

def safe_get(row: pd.Series | dict, keys, default=""):
    if isinstance(row, pd.Series):
        row = row.to_dict()
    for k in keys:
        if k in row:
            v = row.get(k)
            try:
                if pd.isna(v): continue
            except Exception:
                pass
            s = str(v).strip() if v is not None else ""
            if s: return s
    return default

def ensure_output_columns(df: pd.DataFrame) -> pd.DataFrame:
    need = ["å•é¡Œæ–‡","é¸æŠè‚¢1","é¸æŠè‚¢2","é¸æŠè‚¢3","é¸æŠè‚¢4","é¸æŠè‚¢5","æ­£è§£","ç§‘ç›®åˆ†é¡","ãƒªãƒ³ã‚¯URL"]
    out = df.copy()
    for c in need:
        if c not in out.columns: out[c] = ""
    return out

# ===== ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ =====
df = pd.read_csv("97_118DB.csv", dtype=str, encoding="utf-8-sig")
df = df.fillna("")
df = normalize_columns(df)

# ===== æ¤œç´¢ =====
query = st.text_input("å•é¡Œæ–‡ãƒ»é¸æŠè‚¢ãƒ»åˆ†é¡ã§æ¤œç´¢:")
st.caption("ğŸ’¡ æ¤œç´¢èªã‚’ `&` ã§ã¤ãªã’ã‚‹ã¨ANDæ¤œç´¢ï¼ˆä¾‹: ãƒ¬ã‚¸ãƒ³ & ç¡¬ã•ï¼‰")
if not query:
    st.stop()

keywords = [kw.strip() for kw in query.split("&") if kw.strip()]

def row_text(r: pd.Series) -> str:
    parts = [
        safe_get(r, ["å•é¡Œæ–‡","è¨­å•","å•é¡Œ","æœ¬æ–‡"]),
        *[safe_get(r, [f"é¸æŠè‚¢{i}"]) for i in range(1,6)],
        safe_get(r, ["æ­£è§£","è§£ç­”","ç­”ãˆ"]),
        safe_get(r, ["ç§‘ç›®åˆ†é¡","åˆ†é¡","ç§‘ç›®"]),
    ]
    return " ".join([p for p in parts if p])

df_filtered = df[df.apply(
    lambda row: all(kw.lower() in row_text(row).lower() for kw in keywords),
    axis=1
)]
df_filtered = df_filtered.reset_index(drop=True)
st.session_state["df_filtered"] = df_filtered
st.session_state["diagnostic_text"] = row_text(df_filtered.iloc[0]) if len(df_filtered) > 0 else ""

st.info(f"{len(df_filtered)}ä»¶ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸ")

timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
file_prefix = f"{(query if query else 'æ¤œç´¢ãªã—')}{timestamp}"

# ===== CSV =====
csv_buffer = io.StringIO()
ensure_output_columns(df_filtered).to_csv(csv_buffer, index=False)
st.download_button("ğŸ“¥ ãƒ’ãƒƒãƒˆçµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv_buffer.getvalue(), f"{file_prefix}.csv", "text/csv")

# ===== TXT =====
def convert_google_drive_link(url):
    if "drive.google.com" in url and "/file/d/" in url:
        try:
            file_id = url.split("/file/d/")[1].split("/")[0]
            return f"https://drive.google.com/uc?export=view&id={file_id}"
        except Exception:
            return url
    return url

def wrap_text(text: str, max_width: float, font_name: str, font_size: int):
    # â˜…å³å¯†ãƒ¢ãƒ¼ãƒ‰ï¼šç½®æ›ã—ãªã„ã€‚Fallbackãƒ¢ãƒ¼ãƒ‰ã®ã¿ä»£æ›¿è¨˜å·ã«ï¼ˆè¡¨ç¤ºä¸Šã®ä¿é™ºï¼‰
    s = _maybe_fallback_for_pdf("" if text is None else str(text))
    if s == "":
        return [""]
    lines, buf = [], ""
    for ch in s:
        if stringWidth(buf + ch, font_name, font_size) <= max_width:
            buf += ch
        else:
            lines.append(buf); buf = ch
    if buf: lines.append(buf)
    return lines

def wrapped_lines(prefix: str, value: str, usable_width: float, font: str, size: int):
    return wrap_text(f"{prefix}{value}", usable_width, font, size)

def format_record_to_text(row: pd.Series) -> str:
    q = safe_get(row, ["å•é¡Œæ–‡","è¨­å•","å•é¡Œ","æœ¬æ–‡"])
    parts = [f"å•é¡Œæ–‡: {q}"]
    for i in range(1, 6):
        c = safe_get(row, [f"é¸æŠè‚¢{i}"])
        if c: parts.append(f"é¸æŠè‚¢{i}: {c}")
    parts.append(f"æ­£è§£: {safe_get(row, ['æ­£è§£','è§£ç­”','ç­”ãˆ'])}")
    parts.append(f"åˆ†é¡: {safe_get(row, ['ç§‘ç›®åˆ†é¡','åˆ†é¡','ç§‘ç›®'])}")
    link = safe_get(row, ["ãƒªãƒ³ã‚¯URL","ç”»åƒURL","ç”»åƒãƒªãƒ³ã‚¯","ãƒªãƒ³ã‚¯","ç”»åƒLink"])
    if link:
        parts.append(f"ç”»åƒãƒªãƒ³ã‚¯: {convert_google_drive_link(link)}ï¼ˆPDFã«ç”»åƒè¡¨ç¤ºï¼‰")
    return "\n".join(parts)

txt_buffer = io.StringIO()
for _, row in df_filtered.iterrows():
    txt_buffer.write(format_record_to_text(row))
    txt_buffer.write("\n\n" + "-"*40 + "\n\n")
st.download_button("ğŸ“„ ãƒ’ãƒƒãƒˆçµæœã‚’TEXTãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", txt_buffer.getvalue(), f"{file_prefix}.txt", "text/plain")

# ===== PDF =====
def create_pdf(records, progress=None, status=None, start_time=None):
    pdf_buffer = io.BytesIO()
    c = canvas.Canvas(pdf_buffer, pagesize=A4)
    c.setFont(JAPANESE_FONT, 12)
    width, height = A4

    top_margin, bottom_margin = 40, 60
    left_margin, right_margin = 40, 40
    usable_width = width - left_margin - right_margin
    page_usable_h = (height - top_margin) - bottom_margin
    line_h = 18
    y = height - top_margin

    total = len(records)
    if start_time is None: start_time = time.time()

    def fmt(sec):
        m = int(sec // 60); s = int(sec % 60)
        return f"{m:02d}:{s:02d}"

    def new_page():
        nonlocal y
        c.showPage()
        c.setFont(JAPANESE_FONT, 12)
        y = height - top_margin

    def draw_wrapped_lines(lines):
        nonlocal y
        for ln in lines:
            draw_with_fallback(c, left_margin, y, ln, JAPANESE_FONT, 12)
            y -= line_h

    for idx, (_, row) in enumerate(records.iterrows(), start=1):
        q = safe_get(row, ["å•é¡Œæ–‡","è¨­å•","å•é¡Œ","æœ¬æ–‡"])

        # é¸æŠè‚¢
        choices = []
        for i in range(1, 6):
            v = safe_get(row, [f"é¸æŠè‚¢{i}"])
            if v: choices.append((i, v))

        ans = safe_get(row, ["æ­£è§£","è§£ç­”","ç­”ãˆ"])
        cat = safe_get(row, ["ç§‘ç›®åˆ†é¡","åˆ†é¡","ç§‘ç›®"])

        # ç”»åƒã®äº‹å‰å–å¾—
        pil = None; img_est_h = 0
        link_raw = safe_get(row, ["ãƒªãƒ³ã‚¯URL","ç”»åƒURL","ç”»åƒãƒªãƒ³ã‚¯","ãƒªãƒ³ã‚¯"])
        if link_raw:
            try:
                image_url = convert_google_drive_link(link_raw)
                resp = requests.get(image_url, timeout=5)
                pil = Image.open(io.BytesIO(resp.content)).convert("RGB")
                iw, ih = pil.size
                scale = min(usable_width / iw, page_usable_h / ih, 1.0)
                nw, nh = iw * scale, ih * scale
                img_est_h = nh + 20
            except Exception:
                pil = None
                img_est_h = len(wrapped_lines("", "[ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—]", usable_width, JAPANESE_FONT, 12)) * line_h

        # é«˜ã•è¦‹ç©ã‚Š
        est_h = 0
        q_lines = wrapped_lines("å•é¡Œæ–‡: ", q, usable_width, JAPANESE_FONT, 12)
        est_h += len(q_lines) * line_h
        choice_lines_list = []
        for i, v in choices:
            ls = wrapped_lines(f"é¸æŠè‚¢{i}: ", v, usable_width, JAPANESE_FONT, 12)
            choice_lines_list.append(ls); est_h += len(ls) * line_h
        est_h += img_est_h if img_est_h else 0
        ans_lines = wrapped_lines("æ­£è§£: ", ans, usable_width, JAPANESE_FONT, 12)
        cat_lines = wrapped_lines("åˆ†é¡: ", cat, usable_width, JAPANESE_FONT, 12)
        est_h += (len(ans_lines) + len(cat_lines)) * line_h + 20

        # ãƒšãƒ¼ã‚¸å…ˆé ­ã¯å¿…ãšå•é¡Œæ–‡ã‹ã‚‰
        if y - est_h < bottom_margin: new_page()

        # æç”»
        draw_wrapped_lines(q_lines)
        for ls in choice_lines_list: draw_wrapped_lines(ls)

        if pil is not None:
            try:
                iw, ih = pil.size
                scale = min(usable_width / iw, page_usable_h / ih, 1.0)
                nw, nh = iw * scale, ih * scale
                if y - nh < bottom_margin: new_page()
                remaining = y - bottom_margin
                if nh > remaining:
                    adj = remaining / nh
                    nw, nh = nw * adj, nh * adj
                img_io = io.BytesIO(); pil.save(img_io, format="PNG"); img_io.seek(0)
                img_reader = ImageReader(img_io)
                c.drawImage(img_reader, left_margin, y - nh, width=nw, height=nh,
                            preserveAspectRatio=True, mask='auto')
                y -= nh + 20
            except Exception as e:
                err_lines = wrapped_lines("", f"[ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {e}]", usable_width, JAPANESE_FONT, 12)
                draw_wrapped_lines(err_lines)
        else:
            if link_raw:
                draw_wrapped_lines(wrapped_lines("", "[ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—]", usable_width, JAPANESE_FONT, 12))

        draw_wrapped_lines(ans_lines)
        draw_wrapped_lines(cat_lines)

        if y - 20 < bottom_margin: new_page()
        else: y -= 20

        # é€²æ—ï¼†ETA
        if st.session_state.get("progress_on"):
            st.session_state["progress"].progress(min(idx / max(total, 1), 1.0))
            elapsed = time.time() - start_time
            avg_per_item = elapsed / idx if idx > 0 else 0
            remaining = max(total - idx, 0) * avg_per_item
            if "eta_placeholder" in st.session_state:
                st.session_state["eta_placeholder"].markdown(
                    f"â³ æ®‹ã‚Šç›®å®‰: **{int(remaining//60):02d}:{int(remaining%60):02d}**"
                    f"ï¼ˆçµŒé {int(elapsed//60):02d}:{int(elapsed%60):02d} / {idx}/{total} ä»¶ï¼‰"
                )

    c.save()
    pdf_buffer.seek(0)
    return pdf_buffer.getvalue()

# ===== PDF ç”Ÿæˆ =====
if "pdf_bytes" not in st.session_state:
    st.session_state["pdf_bytes"] = None

if st.button("ğŸ–¨ï¸ PDFã‚’ä½œæˆï¼ˆç”»åƒä»˜ãï¼‰"):
    st.session_state["progress_on"] = True
    st.session_state["progress"] = st.progress(0.0)
    st.session_state["eta_placeholder"] = st.empty()

    start = time.time()
    with st.spinner("PDFã‚’ä½œæˆä¸­â€¦"):
        st.session_state["pdf_bytes"] = create_pdf(df_filtered, start_time=start)
    st.session_state["progress_on"] = False

    total_sec = time.time() - start
    st.session_state["eta_placeholder"].markdown(
        f"âœ… å®Œäº†ï¼šåˆè¨ˆ **{int(total_sec//60):02d}:{int(total_sec%60):02d}**"
    )
    st.success("âœ… PDFä½œæˆå®Œäº†ï¼")

if st.session_state["pdf_bytes"] is not None:
    st.download_button(
        "ğŸ“„ ãƒ’ãƒƒãƒˆçµæœã‚’PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        st.session_state["pdf_bytes"],
        f"{file_prefix}.pdf",
        "application/pdf"
    )

# ===== ä¸€è¦§ =====
st.markdown("### ğŸ” ãƒ’ãƒƒãƒˆã—ãŸå•é¡Œä¸€è¦§")
for i, (_, record) in enumerate(df_filtered.iterrows()):
    title = safe_get(record, ["å•é¡Œæ–‡","è¨­å•","å•é¡Œ","æœ¬æ–‡"])
    with st.expander(f"{i+1}. {title[:50]}..."):
        st.markdown("### ğŸ“ å•é¡Œæ–‡")
        st.write(title)

        st.markdown("### âœï¸ é¸æŠè‚¢")
        for j in range(1, 6):
            val = safe_get(record, [f"é¸æŠè‚¢{j}"])
            if val: st.write(f"- {val}")

        show_ans = st.checkbox("æ­£è§£ã‚’è¡¨ç¤ºã™ã‚‹", key=f"show_answer_{i}", value=False)
        if show_ans:
            st.markdown(f"**âœ… æ­£è§£:** {safe_get(record, ['æ­£è§£','è§£ç­”','ç­”ãˆ'])}")
        else:
            st.markdown("**âœ… æ­£è§£:** |||ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§è¡¨ç¤ºï¼‰|||")

        st.markdown(f"**ğŸ“š åˆ†é¡:** {safe_get(record, ['ç§‘ç›®åˆ†é¡','åˆ†é¡','ç§‘ç›®'])}")

        link = safe_get(record, ["ãƒªãƒ³ã‚¯URL","ç”»åƒURL","ç”»åƒãƒªãƒ³ã‚¯","ãƒªãƒ³ã‚¯"])
        if link:
            st.markdown(f"[ç”»åƒãƒªãƒ³ã‚¯ã¯ã“ã¡ã‚‰]({convert_google_drive_link(link)})")
        else:
            st.write("ï¼ˆç”»åƒãƒªãƒ³ã‚¯ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰")
